半开连接数：netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'



一、uptime
Uptime命令的显示结果包括服务器已经运行了多长时间，有多少登陆用户和对服务器性能的总体评估（load average）。load average值分别记录了上个1分钟，5分钟和15分钟间隔的负载情况，load average不是一个百分比，而是在队列中等待执行的进程的数量。如果进程要求CPU时间被阻塞（意味着CPU没有时间处理它），load average值将增加。另一方面，如果每个进程都可以立刻得到访问CPU的时间，这个值将减少。
UP kernel下的load average的最佳值是1，这说明每个进程都可以立刻被CPU处理，当然，更低不会有问题，只说明浪费了一部分的资源。但在不同的系统间这个值也是不同的，例如一个单CPU的工作站，load average为1或者2都是可以接受的，而在一个多CPU的系统中这个值应除以物理CPU的个数，假设CPU个数为4，而load average为8或者10，那结果也是在2多点而已。

 

你可以使用uptime判断一个性能问题是出现在服务器上还是网络上。例如，如果一个网络应用运行性能不理想，运行uptime检查系统负载是否比较高，如果不是这个问题更可能出现在你的网络上。

二、top
Top命令显示了实际CPU使用情况，默认情况下，它显示了服务器上占用CPU的任务信息并且每5秒钟刷新一次。你可以通过多种方式分类它们，包括PID、时间和内存使用情况。

 

下面是输出值的介绍：
引用
PID：进程标识
USER；进程所有者的用户名
PRI：进程的优先级
NI：nice级别
SIZE：进程占用的内存数量（代码＋数据＋堆栈）
RSS；进程使用的物理内存数量
SHARE；该进程和其他进程共享内存的数量
STAT：进程的状态：S＝休眠状态，R＝运行状态，T＝停止状态，D＝中断休眠状态，Z＝僵尸状态
%CPU：共享的CPU使用
%MEM；共享的物理内存
TIME：进程占用CPU的时间
COMMAND：启动任务的命令行（包括参数）

进程的优先级和nice级别
进程优先级是一个决定进程被CPU执行优先顺序的参数，内核会根据需要调整这个值。Nice值是一个对优先权的限制。进程优先级的值不能低于nice值。（nice值越低优先级越高）
进程优先级是无法去手动改变的，只有通过改变nice值去间接的调整进程优先级。如果一个进程运行的太慢了，你可以通过指定一个较低的nice值去为它分配更多的CPU资源。当然，这意味着其他的一些进程将被分配更少的CPU资源，运行更慢一些。Linux支持nice值的范围是19（低优先级）到-20（高优先级），默认的值是0。如果需要改变一个进程的nice值为负数（高优先级），必须使用su命令登陆到root用户。下面是一些调整nice值的命令示例，
以nice值-5开始程序xyz

#nice ?n -5 xyz

改变已经运行的程序的nice值

#renice level pid

将pid为2500的进程的nice值改为10

#renice 10 2500

僵尸进程
当一个进程被结束，在它结束之前通常需要用一些时间去完成所有的任务（比如关闭打开的文件），在一个很短的时间里，这个进程的状态为僵尸状态。在进程完成所有关闭任务之后，会向父进程提交它关闭的信息。有些情况下，一个僵尸进程不能关闭它自己，这时这个进程状态就为z（zombie）。不能使用kill命令杀死僵尸进程，因为它已经标志为“dead”。如果你无法摆脱一个僵尸进程，你可以杀死它的父进程，这个僵尸进程也就消失了。然而，如果父进程是init进程，你不能杀死init进程，因为init是一个重要的系统进程，这种情况下你只能通过一次重新启动服务器来摆脱僵尸进程。也必须分析应用为什么会导致僵死？

三、iostat
iostat是sysstat包的一部分。Iostat显示自系统启动后的平均CPU时间（与uptime类似），它也可以显示磁盘子系统的使用情况，iostat可以用来监测CPU利用率和磁盘利用率。

 

CPU利用率分四个部分：

引用
%user：user level（应用）的CPU占用率情况
%nice：加入nice优先级的user level的CPU占用率情况
%sys：system level（内核）的CPU占用情况
%idle：空闲的CPU资源情况

磁盘占用率有下面几个部分：

引用
Device：块设备名
Tps：设备每秒进行传输的数量（每秒的I/O请求）。多个单独的I/O请求可以被组成一个传输操作，因为一个传输操作可以是不同的容量。
Blk_read/s, Blk_wrtn/s：该设备每秒读写的块的数量。块可能为不同的容量。
Blk_read, Blk_wrtn：自系统启动以来读写的块设备的总量。

块的大小
块可能为不同的容量。块的大小一般为1024、2048、4048byte。可通过tune2fs或dumpe2fs获得：

引用
[root@rfgz ~]# tune2fs -l /dev/hda1|grep 'Block size'
Block size: 4096
[root@rfgz ~]# dumpe2fs -h /dev/hda1|grep 'Block size'
dumpe2fs 1.35 (28-Feb-2004)
Block size: 4096

四、Vmstat
Vmstat命令提供了对进程、内存、页面I/O块和CPU等信息的监控，vmstat可以显示检测结果的平均值或者取样值，取样模式可以提供一个取样时间段内不同频率的监测结果。

 

注：在取样模式中需要考虑在数据收集中可能出现的误差，将取样频率设为比较低的值可以尽可能的减小误差的影响。
下面介绍一下各列的含义

引用
?process（procs）
r：等待运行时间的进程数量
b：处在不可中断睡眠状态的进程
w：被交换出去但是仍然可以运行的进程，这个值是计算出来的
?memoryswpd：虚拟内存的数量
free：空闲内存的数量
buff：用做缓冲区的内存数量
?swap
si：从硬盘交换来的数量
so：交换到硬盘去的数量
?IO
bi：向一个块设备输出的块数量
bo：从一个块设备接受的块数量
?system
in：每秒发生的中断数量， 包括时钟
cs：每秒发生的context switches的数量
?cpu(整个cpu运行时间的百分比)
us：非内核代码运行的时间（用户时间，包括nice时间）
sy：内核代码运行的时间（系统时间）
id：空闲时间，在Linux 2.5.41之前的内核版本中，这个值包括I/O等待时间；
wa：等待I/O操作的时间，在Linux 2.5.41之前的内核版本中这个值为0

Vmstat命令提供了大量的附加参数，下面列举几个十分有用的参数：

引用
?m：显示内核的内存利用率
?a：显示内存页面信息，包括活跃和不活跃的内存页面
?n：显示报头行，这个参数在使用取样模式并将命令结果输出到一个文件时非常有用。例如root#vmstat ?n 2 10以2秒的频率显示10输出结果
?当使用-p 

Unknown macro: {分区} 
时，vmstat提供对I/O结果的统计

 

五、ps和pstree
ps和pstree命令是系统分析最常用的基本命令，ps命令提供了一个正在运行的进程的列表，列出进程的数量取决于命令所附加的参数。例如ps ?A 命令列出所有进程和它们相应的进程ID（PID），进程的PID是使用其他一些工具之前所必须了解的，例如pmap或者renice。
在运行java应用的系统上，ps ?A 命令的输出很容易就会超过屏幕的显示范围，这样就很难得到所有进程的完整信息。这时，使用pstree命令可以以树状结构来显示所有的进程信息并且可以整合子进程的信息。Pstree命令对分析进程的来源十分有用。

 

六、Numastat
随着NUMA架构的不断发展，例如eServer xSeries 445及其后续产品eServer xSeries 460，现在NUMA架构已经成为了企业级数据中心的主流。然而，NUMA架构在性能调优方面面临了新的挑战，例如内存分配的问题在NUMA系统之前并没人感兴趣，而Numastat命令提供了一个监测NUMA架构的工具。Numastat命令提供了本地内存与远程内存使用情况的对比和各个节点的内存使用情况。Numa_miss列显示分配失败的本地内存，numa_foreign列显示分配远程内存（访问速度慢）信息，过多的调用远程内存将增加系统的延迟从而影响整个系统的性能。使运行在一个节点上的进程都访问本地内存将极大的改善系统的性能。

 

※我使用的系统不支持NUMA架构，此图为原文档截图。

七、sar
sar程序也是sysstat安装包的一部分。sar命令用于收集、报告和保存系统的信息。Sar命令由三个应用组成：sar，用与显示数据；sa1和sa2，用于收集和存储数据。默认情况下，系统会在crontab中加入自动收集和分析的操作：

引用
[root@rfgz ~]# cat /etc/cron.d/sysstat
# run system activity accounting tool every 10 minutes
*/10 * * * * root /usr/lib/sa/sa1 1 1
# generate a daily summary of process accounting at 23:53
53 23 * * * root /usr/lib/sa/sa2 -A

sar命令所生成的数据保存在/var/log/sa/目录下，数据按照时间保存，可以根据时间来查询相应的性能数据。
你也可以使用sar在命令行下得到一个实时的执行结果，收集的数据可以包括CPU利用率、内存页面、网络I/O等等。下面的命令表示用sar执行5次，间隔时间为3秒：

 

八、free
free命令显示系统的所有内存的使用情况，包括空闲内存、被使用的内存和交换内存空间。Free命令显示也包括一些内核使用的缓存和缓冲区的信息。
当使用free命令的时候，需要记住linux的内存结构和虚拟内存的管理方法，比如空闲内存数量的限制，还有swap空间的使用并不标志一个内存瓶颈的出现。

 

引用
?-b,-k,-m和-g分别按照bytes, kilobytes, megabytes, gigabytes显示结果。
?-l区别显示low和high内存
?-c 

显示free输出的次数

九、Pmap
pmap命令显示一个或者多个进程使用内存的数量，你可以用这个工具来确定服务器上哪个进程占用了过多的内存从而导致内存瓶颈。

 

十、Strace
strace截取和记录进程的系统调用信息，还包括进程接受的命令信号。这是一个有用的诊断和调试工具，系统管理员可以通过strace来解决程序上的问题。
命令格式，需要指定需要监测的进程ID。这个多为开发人员使用。

strace -p <pid>

十一、ulimit
可以通过ulimit来控制系统资源的使用。请看以前的日志：使用ulimit和proc去调整系统参数 

十二、Mpstat
mpstat命令也是sysstat包的一部分。Mpstat命令用于监测一个多CPU系统中每个可用CPU的情况。Mpstat命令可以显示每个CPU或者所有CPU的运行情况，同时也可以像vmstat命令那样使用参数进行一定频率的采样结果的监测。





1.第一步 配置环境

yum -y install gcc gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel libidn libidn-devel openssl openssl-devel openldap openldap-devel nss_ldap openldap-clients openldap-servers

2.下载nginx代码 

wget http://nginx.org/download/nginx-0.8.54.tar.gz

wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.10.tar.gz

3.vi /etc/sysctl.conf

net.ipv4.tcp_fin_timeout = 30

net.ipv4.tcp_keepalive_time = 300

net.ipv4.tcp_syncookies = 1

net.ipv4.tcp_tw_reuse = 1

net.ipv4.tcp_tw_recycle = 1

net.ipv4.ip_local_port_range = 5000    65000

/sbin/sysctl -p

3.安装pcre

4.安装nginx

./configure --user=www --group=www --prefix=/opt/nginx --with-http_stub_status_module --with-http_ssl_module

nginx 配置参考

user  www www;
worker_processes  8;
error_log  logs/error.log;
pid        logs/nginx.pid;
worker_rlimit_nofile 51200;
events {
    use epoll;
    worker_connections  51200;
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    server_names_hash_bucket_size 128;
    client_header_buffer_size 32k;
    large_client_header_buffers 4 32k;
    client_max_body_size 8m;
    sendfile        on;
    tcp_nopush     on;
    keepalive_timeout  65;
    tcp_nodelay on;
    gzip  on;
    gzip_min_length  1k;
    gzip_buffers     4 16k;
    gzip_http_version 1.0;
    gzip_comp_level 2;
    gzip_types       text/plain application/x-javascript text/css application/xml;
    gzip_vary on;
    include       /data/www/life/config/life.nginx.conf;
}







nf_conntrack: table full, dropping packet.

If you see this message "nf_conntrack: table full, dropping packet" in your syslog on a Linux box, it's likely that it's having comms problems. I saw this recently on a DNS server that looked like it was being attacked. The problem is that when this happens, normal DNS resolution is interrupted.

I haven't found a decent solution yet, but it seems that if the system has lots of RAM then you can increase the nf_conntrack_max kernel parameter (my system is running iptables, which I assume the "netfilter" module has something to do with).

On a 2.6 kernel, you can go to /proc/sys/net/netfilter and check some of the values. For instance, nf_conntrack_count shows you the current value while nf_conntrack_max is the maximum value that is set.

You can just cat these values or use sysctl to view them:

# sysctl net.netfilter.nf_conntrack_max
net.netfilter.nf_conntrack_max = 65536

# sysctl net.netfilter.nf_conntrack_count
net.netfilter.nf_conntrack_count = 45033

To change the value, use the -w switch (in this example I've doubled the value):

# sysctl -w net.netfilter.nf_conntrack_max=131072

I think that in order to make this permanent across reboots, you'll need to add this line to the bottom of /etc/sysctl.conf:

net.netfilter.nf_conntrack_max=131072


解决方法：

net.netfilter.nf_conntrack_max = 655360
net.netfilter.nf_conntrack_tcp_timeout_established = 180

-----

net.ipv4.icmp_echo_ignore_broadcasts = 1
net.ipv4.conf.all.rp_filter = 1
fs.inotify.max_user_watches = 65536
net.ipv4.conf.default.promote_secondaries = 1
net.ipv4.conf.all.promote_secondaries = 1
kernel.msgmnb = 65536
kernel.msgmax = 65536
kernel.shmmax = 68719476736
kernel.shmall = 4294967296
net.ipv4.route.gc_interval = 1
net.ipv4.route.gc_timeout = 150
net.ipv4.route.gc_elasticity = 2
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.ip_local_port_range = 1024    65000
net.core.rmem_max = 16777216
net.core.wmem_default = 8388608
net.core.wmem_max=16777216
net.core.rmem_default = 16777216
net.core.netdev_max_backlog = 262144
net.core.somaxconn = 262144
net.ipv4.tcp_max_orphans = 3276800
net.ipv4.tcp_max_syn_backlog = 262144
net.ipv4.tcp_synack_retries = 2
net.ipv4.tcp_retries2=7
net.ipv4.tcp_rmem=4096 87380 16777216
net.ipv4.tcp_wmem=4096 65536 16777216
net.ipv4.tcp_mem = 94500000 915000000 927000000
net.ipv4.tcp_timestamps=0
net.ipv4.tcp_window_scaling= 1
net.ipv4.tcp_fin_timeout = 1
net.ipv4.tcp_sack=1
net.ipv4.tcp_no_metrics_save=1
net.ipv4.tcp_syn_retries = 2
net.ipv4.tcp_keepalive_time=30
net.ipv4.tcp_keepalive_probes=2
net.ipv4.tcp_keepalive_intvl=2
net.ipv4.tcp_max_tw_buckets = 1200000
net.ipv4.ip_conntrack_max = 655360
net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180

或者###

fs01:~ # lsmod | grep conntrack
nf_conntrack_ipv4      12792  3 iptable_nat,nf_nat
nf_conntrack           80480  3 iptable_nat,nf_nat,nf_conntrack_ipv4

 

rmmod   nf_conntrack_ipv4   nf_conntrack  




最近经常写网络方面的东西，总是碰到相同的问题，无论机器多好，cpu多么的空闲，内存多么宽松，9000个连接后，服务器就睡觉去了。。。气死我了。后来才发现，有个设置问题。

这个设置在 /proc/sys/net/nf_conntrack_max下，可以在启动的时候，通过

/etc/sysctl.conf设置，内容如下

net.netfilter.nf_conntrack_max=65528
net.ipv4.netfilter.ip_conntrack_max=65535


net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 1200


The ip_conntrack module uses a portion of the system memory to track connections called a  connection tracking table. The size of this table is set when the ip_conntrack module is loaded, and is usually determined automatically by a hash of the installed system RAM. For example, a system with 256MB RAM will typically have a conntrack table of 8192 entries by default.
 
The maximum number of connections that can maintained is  8*hashsize of the connection tracking module and each connection tracking requires approximately 300bytes
 
To check the maximum conntrack entries available, look at the proc file system:
 
[root@localhost ~]# cat /proc/sys/net/ipv4/ip_conntrack_max
8192
 
If the message in the system's logs is ip_conntrack: table full, dropping packet. it means that the table is full, and packets that are traversing the system's firewall are being dropped.




列举所有数据库的磁盘空间占用情况

 
select TABLE_SCHEMA, concat(truncate(sum(data_length)/1024/1024,2),' MB') as data_size,
concat(truncate(sum(index_length)/1024/1024,2),' MB') as index_size
from information_schema.tables
group by TABLE_SCHEMA
order by data_length desc;

列举某个数据库下面各个表的磁盘空间占用情况

	
select TABLE_NAME, concat(truncate(data_length/1024/1024,2),' MB') as data_size,
concat(truncate(index_length/1024/1024,2),' MB') as index_size
from information_schema.tables where TABLE_SCHEMA = 'database_name'
group by TABLE_NAME
order by data_length desc;





export HISTTIMEFORMAT="%h/%d - %H:%M:%S "
